# Cortideri Ingestion Script

## What it does

Transforms `cortideri_items` into `knowledge_chunks` with:

1. **Intelligent Chunking**: Splits articles >1500 tokens by paragraphs
2. **Vector Embeddings**: Generates embeddings using OpenAI `text-embedding-3-small` (batched for
   efficiency)
3. **Deduplication**: Uses `text_hash` to avoid duplicate chunks
4. **Document Tracking**: Creates/updates `document_sources` entries
5. **Idempotency**: Re-running the script only processes changed articles

## Prerequisites

- âœ… Migration `001_rag_infrastructure.sql` applied
- âœ… `OPENAI_API_KEY` in `.env` or configured via vault (see `docs/CONFIGURATION_VAULT.md`)
- âœ… `cortideri_items` table populated (run `npm run scrape:cortideri` first)

## Usage

```bash
node scripts/ingest_cortideri_chunks.js
```

## What happens

For each article in `cortideri_items`:

1. **Check if changed**: Compare `content_hash` in `document_sources`
2. **Skip if unchanged**: Idempotent behavior
3. **Chunk the article**:
   - â‰¤1500 tokens â†’ 1 chunk
   - \>1500 tokens â†’ Split by paragraphs
4. **Generate embeddings**: OpenAI API call for each chunk
5. **Insert into `knowledge_chunks`**: With deduplication via `text_hash`
6. **Update `synced_at`**: Mark article as processed

## Output example

```
ðŸ“„ Processing: Mairie de Corte â€“ Conseil Municipal de Toussaint Pierucci
  Source created: cortideri:10657
  ðŸ“¦ Chunks: 3
  ðŸ”¹ Chunk 1/3: queued for embedding
  ðŸ”¹ Chunk 2/3: queued for embedding
  ðŸ”¹ Chunk 3/3: queued for embedding
    Processing 1 embedding batch(es)...
    Batch 1/1: 3 chunks
    Generating embeddings for 3 chunks...
    Inserting 3 chunks...
    Total inserted: 3 chunks
  âœ… Done (3/3 new chunks)
```

## Cost estimation

- **Embeddings**: ~$0.00002 per 1000 tokens
- **454 articles** Ã— ~1000 tokens avg = ~$0.01 total

## Troubleshooting

### Error: "vector type not found"

â†’ Run migration to enable `pgvector` extension

### Error: "OPENAI_API_KEY not found"

â†’ Add to `.env` file or configure via the vault system (see `docs/CONFIGURATION_VAULT.md`)

### Chunks not appearing

â†’ Check `knowledge_chunks` table:

```sql
SELECT COUNT(*) FROM knowledge_chunks;
```

## Next steps

After ingestion:

1. Verify chunks: `SELECT * FROM knowledge_chunks LIMIT 10;`
2. Test vector search
3. Update chatbot to use RAG
